ğŸ‘” TalentScout â€“ AI-Powered Hiring Assistant Chatbot

TalentScout is an intelligent AI-powered chatbot built using Python, Streamlit, and Large Language Models (LLMs) that automates the initial candidate screening process for technical roles.

Unlike traditional fixed-question systems, TalentScout dynamically generates 3â€“5 tailored technical interview questions per technology based on the candidateâ€™s declared tech stack.

ğŸ“‹ Project Overview

TalentScout is designed to streamline and modernize the initial hiring workflow by:

ğŸ¤– Automating candidate screening

ğŸ§  Dynamically generating tech-specific interview questions

ğŸ“Š Maintaining context-aware conversations

ğŸ” Handling candidate data securely within session

ğŸ’¼ Delivering a professional recruiter-like experience

â­ Key Capabilities
ğŸ”„ Multi-Step Intelligent Conversation Flow

Greeting â†’ Information Collection â†’ Tech Stack Analysis â†’ Dynamic Technical Questions â†’ Graceful Exit

ğŸ§¾ Structured Candidate Data Collection

Full Name

Email Address (validated)

Phone Number

Years of Experience

Desired Position

Current Location

Tech Stack

ğŸ§  Dynamic Technical Question Generation

3â€“5 questions per technology

Medium-level difficulty

Technology-specific

No generic or irrelevant questions

ğŸ’¬ Context Retention

Uses Streamlit session_state

Maintains full conversation history

Handles follow-ups smoothly

ğŸ›‘ Smart Exit Handling

Recognizes:

exit, quit, bye, thank you, stop, end

Ends conversation professionally.

ğŸš€ Installation Steps
ğŸ”¹ Prerequisites

Python 3.8 or higher

OpenAI API Key

ğŸ”¹ Step-by-Step Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/talentscout-chatbot.git
cd talentscout-chatbot
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Set Environment Variables

Create .env file:

OPENAI_API_KEY=your_actual_api_key_here
4ï¸âƒ£ Run the Application
streamlit run app.py

The app runs at:

http://localhost:8501
ğŸ“– Usage Instructions
ğŸ‘¤ For Candidates

1ï¸âƒ£ The chatbot greets you automatically

2ï¸âƒ£ Provide information step-by-step:

Full Name

Email

Phone

Experience

Desired Role

Location

3ï¸âƒ£ Enter your Tech Stack (comma-separated):

Example:

Python, Django, PostgreSQL, Docker

4ï¸âƒ£ The AI generates technical questions for EACH technology

5ï¸âƒ£ Answer the questions

6ï¸âƒ£ The chatbot ends with:

"Thank you for your time. Our team will review your responses and contact you soon."

ğŸ§  Prompt Design Explanation

This project heavily focuses on Prompt Engineering, which is 30% of the evaluation criteria.

ğŸ”¹ Information Gathering Prompt

Designed to:

Ask only one question at a time

Maintain context

Avoid deviation from hiring purpose

Handle unclear responses

ğŸ”¹ Technical Question Generation Prompt

Example structure:

TECH_PROMPT = """
You are a senior technical interviewer.

Based on the tech stack: {tech_stack}

Generate 3-5 medium-level technical interview questions per technology.
Do not provide answers.
Format clearly under each technology.
"""
ğŸ¯ Why This Works:

Role-based prompting

Clear formatting instructions

Difficulty control

Structured output enforcement

ğŸ”¹ Fallback Prompt Strategy

If input is unclear:

Politely redirect conversation

Stay within hiring context

Avoid unrelated answers

ğŸ—ï¸ Technical Decisions
1ï¸âƒ£ Streamlit for UI

âœ” Rapid development
âœ” Built-in session management
âœ” Ideal for chat-based apps

2ï¸âƒ£ LLM for Dynamic Question Generation

âœ” Handles diverse tech stacks
âœ” No hardcoded questions
âœ” Scalable for unlimited technologies
âœ” More realistic interview simulation

3ï¸âƒ£ Session-Based Storage

âœ” No external database
âœ” Data persists during session only
âœ” GDPR-conscious design
âœ” No permanent sensitive storage

4ï¸âƒ£ Modular Prompt Design

Separated prompts for:

Info collection

Technical generation

Fallback handling

Improves maintainability and clarity.

ğŸš§ Challenges Faced
1. Maintaining Context

Problem: LLM forgetting earlier details
Solution: Stored conversation in session_state

2. Off-Topic Responses

Problem: Model drifting from hiring process
Solution: Strong role-based system prompts

3. Diverse Tech Stacks

Problem: Handling unlimited technologies
Solution: Dynamic prompt template with tech substitution

4. Exit Handling

Problem: Abrupt conversation termination
Solution: Implemented keyword-based graceful closing

ğŸ¤– Model Details

Model Used: GPT-based LLM
Temperature: 0.6â€“0.7 (balanced creativity & structure)
Max Tokens: 500

Prompt Format:
messages = [
    {"role": "system", "content": "You are an AI Hiring Assistant for TalentScout."},
    {"role": "user", "content": user_input}
]
ğŸ“ Project Structure
talentscout-chatbot/
â”œâ”€â”€ app.py
â”œâ”€â”€ prompts.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ”’ Security Notes

API key stored in .env

.env added to .gitignore

No permanent candidate data storage

Session-based information handling

ğŸ“ Sample Data Output (Session Simulation)
{
  "full_name": "John Doe",
  "email": "john@example.com",
  "phone": "+91-9876543210",
  "years_experience": "4",
  "desired_position": "Backend Developer",
  "tech_stack": ["Python", "Django"]
}
ğŸ† Why This Project Stands Out

Demonstrates practical LLM application

Strong prompt engineering focus

Clean UI and user experience

Context-aware conversational AI

Recruiter-ready simulation


happy hiringğŸ˜Š 
